{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01de8400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.8.8 (default, Apr 13 2021, 12:59:45) \n",
      "[Clang 10.0.0 ]\n",
      "Spark version: 3.1.2\n"
     ]
    }
   ],
   "source": [
    "import recommenders\n",
    "# set the environment path to find Recommenders\n",
    "import sys\n",
    "import pyspark\n",
    "from pyspark.ml.recommendation import ALS\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import StringType, FloatType, IntegerType, LongType\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "#from recommenders.datasets import movielens\n",
    "from recommenders.utils.notebook_utils import is_jupyter\n",
    "from recommenders.datasets.spark_splitters import spark_random_split\n",
    "from recommenders.evaluation.spark_evaluation import SparkRatingEvaluation, SparkRankingEvaluation\n",
    "from recommenders.utils.spark_utils import start_or_get_spark\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Spark version: {}\".format(pyspark.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1943b89",
   "metadata": {},
   "source": [
    "## PySpark Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "168dc768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following settings work well for debugging locally on VM - change when running on a cluster\n",
    "# set up a giant single executor with many threads and specify memory cap\n",
    "spark = start_or_get_spark(\"ALS PySpark\", memory=\"16g\")\n",
    "spark.conf.set(\"spark.sql.analyzer.failAmbiguousSelfJoin\", \"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e67a3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType\n",
    "\n",
    "# 创建Spark会话\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ALS PySpark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# 从CSV文件加载数据\n",
    "data = pd.read_csv(\"../data/df_for_CF_cleaned.csv\")\n",
    "\n",
    "# 选择需要的列，并重置索引\n",
    "df_all = data.loc[:,[\"iid\",\"pid\",\"dec\"]].reset_index(drop=True)\n",
    "\n",
    "# 为列指定新的名称\n",
    "p_col = ['userID','itemID','rating']\n",
    "df_all.columns = p_col\n",
    "\n",
    "# 定义Schema\n",
    "schema = StructType([\n",
    "    StructField(\"userID\", IntegerType()),\n",
    "    StructField(\"itemID\", IntegerType()),\n",
    "    StructField(\"rating\", FloatType())\n",
    "])\n",
    "\n",
    "# 将Pandas DataFrame 转换为Spark DataFrame\n",
    "spark_df = spark.createDataFrame(df_all.astype({\"userID\": int, \"itemID\": int, \"rating\": float}), schema=schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b69c351a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[userID: int, itemID: int, rating: float]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a7bd9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N train 6084\n",
      "N test 1938\n"
     ]
    }
   ],
   "source": [
    "data = spark_df\n",
    "train, test = spark_random_split(data, ratio=0.75, seed=123)\n",
    "print (\"N train\", train.cache().count())\n",
    "print (\"N test\", test.cache().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befb538c",
   "metadata": {},
   "source": [
    "## Train the ALS model on the training data, and get the top-k recommendations for our testing data\n",
    "\n",
    "To predict movie ratings, we use the rating data in the training set as users' explicit feedback. The hyperparameters used in building the model are referenced from [here](http://mymedialite.net/examples/datasets.html). We do not constrain the latent factors (`nonnegative = False`) in order to allow for both positive and negative preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "406cb8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# Select MovieLens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '100k'\n",
    "\n",
    "# Column names for the dataset\n",
    "COL_USER = \"userID\"\n",
    "COL_ITEM = \"itemID\"\n",
    "COL_RATING = \"rating\"\n",
    "COL_TIMESTAMP = \"Timestamp\"\n",
    "\n",
    "header = {\n",
    "    \"userCol\": COL_USER,\n",
    "    \"itemCol\": COL_ITEM,\n",
    "    \"ratingCol\": COL_RATING,\n",
    "}\n",
    "\n",
    "\n",
    "als = ALS(\n",
    "    rank=10,\n",
    "    maxIter=15,\n",
    "    implicitPrefs=False,\n",
    "    regParam=0.05,\n",
    "    coldStartStrategy='drop',\n",
    "    nonnegative=False,\n",
    "    seed=42,\n",
    "    **header\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9659dd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 4.106173681999962 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    model = als.fit(train)\n",
    "\n",
    "print(\"Took {} seconds for training.\".format(train_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0b3bd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 20.73038315200006 seconds for prediction.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as test_time:\n",
    "\n",
    "    # Get the cross join of all user-item pairs and score them.\n",
    "    users = train.select(COL_USER).distinct()\n",
    "    items = train.select(COL_ITEM).distinct()\n",
    "    user_item = users.crossJoin(items)\n",
    "    dfs_pred = model.transform(user_item)\n",
    "\n",
    "    # Remove seen items.\n",
    "    dfs_pred_exclude_train = dfs_pred.alias(\"pred\").join(\n",
    "        train.alias(\"train\"),\n",
    "        (dfs_pred[COL_USER] == train[COL_USER]) & (dfs_pred[COL_ITEM] == train[COL_ITEM]),\n",
    "        how='outer'\n",
    "    )\n",
    "\n",
    "    top_all = dfs_pred_exclude_train.filter(dfs_pred_exclude_train[f\"train.{COL_RATING}\"].isNull()) \\\n",
    "        .select('pred.' + COL_USER, 'pred.' + COL_ITEM, 'pred.' + \"prediction\")\n",
    "\n",
    "    # In Spark, transformations are lazy evaluation\n",
    "    # Use an action to force execute and measure the test time \n",
    "    top_all.cache().count()\n",
    "\n",
    "print(\"Took {} seconds for prediction.\".format(test_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f89d7c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------------+\n",
      "|userID|itemID|  prediction|\n",
      "+------+------+------------+\n",
      "|     2|    80| -0.36090994|\n",
      "|     2|   303|   0.7053553|\n",
      "|     2|   472| -0.52474487|\n",
      "|     3|    22|         0.0|\n",
      "|     3|    57|         0.0|\n",
      "|     3|    89|         0.0|\n",
      "|     3|   367|         0.0|\n",
      "|     4|   185| -0.17475829|\n",
      "|     4|   405|  0.05618856|\n",
      "|     4|   457|  0.12476618|\n",
      "|     5|   225|  0.19171292|\n",
      "|     6|   117| 0.093515545|\n",
      "|     6|   274|   0.5912022|\n",
      "|     6|   327|-0.098053694|\n",
      "|     6|   393| 0.024363607|\n",
      "|     6|   408|  -0.3395221|\n",
      "|     6|   520|  -0.5121326|\n",
      "|     7|    55| -0.04255647|\n",
      "|     7|   132|   0.6185148|\n",
      "|     7|   475|  0.45173293|\n",
      "+------+------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_all.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f5b52c",
   "metadata": {},
   "source": [
    "## Evaluate how well ALS performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e36bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_eval = SparkRankingEvaluation(test, top_all, k = TOP_K, col_user=COL_USER, col_item=COL_ITEM, \n",
    "                                    col_rating=COL_RATING, col_prediction=\"prediction\", \n",
    "                                    relevancy_method=\"top_k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf641ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\tALS\n",
      "Top K:\t10\n",
      "MAP:\t0.035411\n",
      "NDCG:\t0.069272\n",
      "Precision@K:\t0.036364\n",
      "Recall@K:\t0.098300\n"
     ]
    }
   ],
   "source": [
    "print(\"Model:\\tALS\",\n",
    "      \"Top K:\\t%d\" % rank_eval.k,\n",
    "      \"MAP:\\t%f\" % rank_eval.map_at_k(),\n",
    "      \"NDCG:\\t%f\" % rank_eval.ndcg_at_k(),\n",
    "      \"Precision@K:\\t%f\" % rank_eval.precision_at_k(),\n",
    "      \"Recall@K:\\t%f\" % rank_eval.recall_at_k(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ec2756e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+----------+\n",
      "|userID|itemID|rating|prediction|\n",
      "+------+------+------+----------+\n",
      "|   163|   148|   0.0|0.23417708|\n",
      "|   173|   148|   0.0|0.97054243|\n",
      "|   494|   471|   1.0| 0.3461488|\n",
      "|   490|   471|   1.0| 0.7004903|\n",
      "|   488|   471|   0.0|0.47787538|\n",
      "|   483|   471|   0.0|0.11732125|\n",
      "|   503|   496|   1.0| 0.5846836|\n",
      "|   235|   243|   1.0|       0.0|\n",
      "|   400|   392|   0.0| 0.5791444|\n",
      "|   399|   392|   0.0|       0.0|\n",
      "|   401|   392|   0.0|       0.0|\n",
      "|   530|   540|   1.0|0.20571373|\n",
      "|   519|   540|   0.0|       0.0|\n",
      "|   509|   540|   1.0|0.14940831|\n",
      "|    54|    31|   1.0| 0.6736362|\n",
      "|    48|    31|   1.0| 0.3251678|\n",
      "|    43|    31|   1.0|0.93497974|\n",
      "|    50|    31|   1.0| 0.9269944|\n",
      "|   539|   516|   1.0| 0.5122782|\n",
      "|   531|   516|   1.0|0.14309825|\n",
      "+------+------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate predicted ratings.\n",
    "prediction = model.transform(test)\n",
    "prediction.cache().show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79d0bda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\tALS rating prediction\n",
      "RMSE:\t0.476986\n",
      "MAE:\t0.364778\n",
      "Explained variance:\t0.114680\n",
      "R squared:\t0.063770\n"
     ]
    }
   ],
   "source": [
    "rating_eval = SparkRatingEvaluation(test, prediction, col_user=COL_USER, col_item=COL_ITEM, \n",
    "                                    col_rating=COL_RATING, col_prediction=\"prediction\")\n",
    "\n",
    "print(\"Model:\\tALS rating prediction\",\n",
    "      \"RMSE:\\t%f\" % rating_eval.rmse(),\n",
    "      \"MAE:\\t%f\" % rating_eval.mae(),\n",
    "      \"Explained variance:\\t%f\" % rating_eval.exp_var(),\n",
    "      \"R squared:\\t%f\" % rating_eval.rsquared(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdf51ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup spark instance\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51b3869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
